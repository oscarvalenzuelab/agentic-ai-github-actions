name: AI-Powered Dependency Analysis

on:
  workflow_dispatch:
    inputs:
      analysis_type:
        description: 'Type of analysis to perform'
        required: true
        default: 'comprehensive'
        type: choice
        options:
          - comprehensive
          - security-focused
          - maintainer-burnout
          - community-health
          - license-compliance
  schedule:
    - cron: '0 4 * * WED'  # Weekly on Wednesday at 4 AM
  push:
    branches: [ main ]
    paths:
      - 'package.json'
      - 'analysis-prompts/**'

permissions: read-all

jobs:
  ai-analysis:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      issues: write
      pull-requests: read
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Extract dependency data
        run: |
          node scripts/extract-dependencies.js > dependencies.json
          echo "Found $(cat dependencies.json | jq '.repositories | length') repositories to analyze"

      - name: Collect GitHub repository metrics
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          mkdir -p repo-data
          
          # For each dependency, collect comprehensive GitHub data
          cat dependencies.json | jq -r '.repositories[]' | while read -r repo; do
            if [[ "$repo" == *"github.com"* ]]; then
              repo_path=$(echo "$repo" | sed 's/.*github.com\///' | sed 's/.git$//')
              safe_name=$(echo "$repo_path" | sed 's/\//_/g')
              
              echo "Collecting data for $repo_path..."
              
              # Repository overview
              gh api repos/$repo_path > "repo-data/${safe_name}_overview.json" || echo "{}" > "repo-data/${safe_name}_overview.json"
              
              # Contributors and commit activity
              gh api repos/$repo_path/stats/contributors > "repo-data/${safe_name}_contributors.json" || echo "[]" > "repo-data/${safe_name}_contributors.json"
              
              # Recent commits
              gh api repos/$repo_path/commits?per_page=100 > "repo-data/${safe_name}_commits.json" || echo "[]" > "repo-data/${safe_name}_commits.json"
              
              # Issues and PRs
              gh api repos/$repo_path/issues?state=all&per_page=100 > "repo-data/${safe_name}_issues.json" || echo "[]" > "repo-data/${safe_name}_issues.json"
              
              # Community health
              gh api repos/$repo_path/community/profile > "repo-data/${safe_name}_community.json" || echo "{}" > "repo-data/${safe_name}_community.json"
              
              # Releases
              gh api repos/$repo_path/releases?per_page=10 > "repo-data/${safe_name}_releases.json" || echo "[]" > "repo-data/${safe_name}_releases.json"
              
              sleep 1  # Rate limiting
            fi
          done

      - name: Prepare analysis context
        run: |
          node scripts/prepare-analysis-context.js repo-data/ > analysis-context.json

      - name: Run AI analysis
        if: github.event.inputs.analysis_type != '' || github.event_name == 'schedule'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          ANALYSIS_TYPE: ${{ github.event.inputs.analysis_type || 'comprehensive' }}
        run: |
          # Select appropriate prompt based on analysis type
          PROMPT_FILE="analysis-prompts/${ANALYSIS_TYPE}.md"
          
          if [ ! -f "$PROMPT_FILE" ]; then
            PROMPT_FILE="analysis-prompts/comprehensive.md"
          fi
          
          # Check if OpenAI API key is available
          if [ -n "${{ secrets.OPENAI_API_KEY }}" ]; then
            echo "Using OpenAI for analysis..."

            # Export the API key for the Node script
            export OPENAI_API_KEY="${{ secrets.OPENAI_API_KEY }}"

            # Use the improved Node.js script for OpenAI analysis
            if [ -f "scripts/test-openai-analysis.js" ]; then
              node scripts/test-openai-analysis.js
            else
              # Fallback to curl approach with better error handling
              echo "Script not found, using curl fallback..."

              # Create summarized context to avoid token limits
              SUMMARIZED_CONTEXT=$(node -e "
              const fs = require('fs');
              const context = JSON.parse(fs.readFileSync('analysis-context.json', 'utf8'));
              const summary = {
                date: context.analysisDate,
                repos: context.repositoriesAnalyzed,
                avgScore: context.summary.averageHealthScore,
                topConcerns: context.detailedAnalysis
                  .filter(r => r.healthScore < 50)
                  .slice(0, 5)
                  .map(r => ({
                    name: r.repository,
                    score: r.healthScore,
                    issue: r.metrics.archived ? 'archived' :
                           r.metrics.disabled ? 'disabled' :
                           r.metrics.commitsLastMonth === 0 ? 'no activity' :
                           r.metrics.contributorCount < 2 ? 'low contributors' : 'low health'
                  }))
              };
              console.log(JSON.stringify(summary));
              ")

              # Create a temporary file for the response
              TEMP_RESPONSE=$(mktemp)

              # Call OpenAI API with smaller context
              curl -s https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer ${{ secrets.OPENAI_API_KEY }}" \
                -d @- <<EOF > $TEMP_RESPONSE
              {
                "model": "gpt-3.5-turbo-16k",
                "messages": [
                  {
                    "role": "system",
                    "content": "You are an expert in open source software analysis. Provide concise JSON response."
                  },
                  {
                    "role": "user",
                    "content": "Analyze these dependency metrics and provide recommendations:\n\n$SUMMARIZED_CONTEXT\n\nRespond with JSON containing: summary (2-3 sentences), overallRisk (Low/Medium/High/Critical), criticalFindings (array of 3-5 issues), securityIssues (array), sustainabilityIssues (array), recommendations (array of 5 actions), immediateActions (array of 2-3 urgent items)"
                  }
                ],
                "temperature": 0.3,
                "max_tokens": 2000
              }
          EOF

              # Extract and process the response
              if jq -e '.choices[0].message.content' $TEMP_RESPONSE > /dev/null 2>&1; then
                jq -r '.choices[0].message.content' $TEMP_RESPONSE > ai-analysis-raw.txt

                # Try to parse as JSON, or create structured response
                node -e "
                const fs = require('fs');
                const raw = fs.readFileSync('ai-analysis-raw.txt', 'utf8');
                let result;
                try {
                  result = JSON.parse(raw);
                } catch(e) {
                  result = {
                    summary: raw,
                    overallRisk: 'Medium',
                    criticalFindings: [],
                    securityIssues: [],
                    sustainabilityIssues: [],
                    recommendations: ['Review the analysis summary above'],
                    immediateActions: []
                  };
                }
                fs.writeFileSync('ai-analysis-result.json', JSON.stringify(result, null, 2));
                " || echo '{"summary": "Analysis failed", "overallRisk": "Unknown"}' > ai-analysis-result.json
              else
                echo "OpenAI API call failed. Response:"
                cat $TEMP_RESPONSE
                echo '{"summary": "OpenAI API call failed", "overallRisk": "Unknown"}' > ai-analysis-result.json
              fi

              rm -f $TEMP_RESPONSE
            fi
          else
            echo "No AI service configured. Generating enhanced rule-based analysis for type: ${ANALYSIS_TYPE}..."
            
            # Use enhanced rule-based analysis for specific analysis types
            if [ -f "scripts/enhanced-rule-analysis.js" ]; then
              node scripts/enhanced-rule-analysis.js analysis-context.json "${ANALYSIS_TYPE}" > ai-analysis-result.json
            else
              # Fallback to basic analysis
              node -e "
              const context = require('./analysis-context.json');
              const analysis = {
                summary: 'Automated Analysis (No AI Service Available)',
                findings: [],
                recommendations: []
              };
              
              // Analyze health scores
              const avgScore = context.summary.averageHealthScore;
              if (avgScore < 50) {
                analysis.findings.push('‚ö†Ô∏è Low average health score (' + avgScore + '/100) across dependencies');
                analysis.recommendations.push('Consider replacing or contributing to low-health dependencies');
              }
              
              // Check for at-risk repos
              const atRisk = context.summary.atRiskRepositories;
              if (atRisk > 0) {
                analysis.findings.push('üî¥ ' + atRisk + ' repositories identified as at-risk');
                analysis.recommendations.push('Prioritize reviewing at-risk dependencies for replacement');
              }
              
              // Check for abandoned repos
              context.detailedAnalysis.forEach(repo => {
                if (repo.metrics.archived) {
                  analysis.findings.push('‚ùå ' + repo.repository + ' is archived');
                }
                if (repo.metrics.commitsLastMonth === 0 && !repo.metrics.archived) {
                  analysis.findings.push('‚ö†Ô∏è ' + repo.repository + ' has no recent activity');
                }
                if (repo.metrics.contributorCount < 2) {
                  analysis.findings.push('üë§ ' + repo.repository + ' has bus factor risk (single maintainer)');
                }
              });
              
              // Output formatted analysis
              console.log('## Analysis Results\\n');
              console.log('### Key Findings\\n');
              analysis.findings.forEach(f => console.log('- ' + f));
              console.log('\\n### Recommendations\\n');
              analysis.recommendations.forEach(r => console.log('- ' + r));
              
              // Add metrics summary
              console.log('\\n### Metrics Summary\\n');
              console.log('- Total repositories analyzed: ' + context.repositoriesAnalyzed);
              console.log('- Average health score: ' + avgScore + '/100');
              console.log('- Healthy repositories: ' + context.summary.healthyRepositories);
              console.log('- At-risk repositories: ' + atRisk);
            " > ai-analysis-result.json
            fi
          fi

      - name: Generate detailed reports
        run: |
          # Check if AI analysis completed successfully
          if [ ! -f "ai-analysis-result.json" ]; then
            echo "AI analysis file not found. Creating fallback analysis..."
            echo "# Analysis Not Available" > ai-analysis-result.json
            echo "Analysis could not be completed. Please check previous steps." >> ai-analysis-result.json
          fi

          # Create markdown report from AI analysis
          node scripts/format-ai-report.js ai-analysis-result.json analysis-context.json > ai-analysis-report.md

          # Generate risk matrix
          node scripts/generate-risk-matrix.js repo-data/ > risk-matrix.json

          # Create actionable insights
          node scripts/generate-insights.js ai-analysis-result.json risk-matrix.json > actionable-insights.md

      - name: Create summary dashboard
        run: |
          cat > dependency-dashboard.md << EOF
          # Dependency Analysis Dashboard
          
          ## Analysis Summary
          - **Date**: $(date)
          - **Analysis Type**: ${{ github.event.inputs.analysis_type || 'comprehensive' }}
          - **Total Dependencies Analyzed**: $(cat dependencies.json | jq '.packages | length')
          - **GitHub Repositories Analyzed**: $(cat dependencies.json | jq '.repositories | length')
          
          ## Key Findings
          $(cat ai-analysis-report.md | head -50)
          
          ## Risk Assessment
          $(cat risk-matrix.json | jq -r '.summary')
          
          ## Actionable Insights
          $(cat actionable-insights.md)
          
          ---
          *Full reports available in workflow artifacts*
          EOF

      - name: Upload analysis artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ai-dependency-analysis
          path: |
            repo-data/
            analysis-context.json
            ai-analysis-result.json
            ai-analysis-report.md
            risk-matrix.json
            actionable-insights.md
            dependency-dashboard.md

      - name: Create or update analysis issue
        if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const dashboard = fs.readFileSync('dependency-dashboard.md', 'utf8');
            const insights = fs.readFileSync('actionable-insights.md', 'utf8');
            
            const title = `AI Dependency Analysis - ${new Date().toISOString().split('T')[0]}`;
            
            // Check if issue already exists
            const issues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              labels: 'ai-analysis,dependencies',
              state: 'open'
            });
            
            const existingIssue = issues.data.find(i => i.title.includes('AI Dependency Analysis'));
            
            const body = `${dashboard}\n\n## Detailed Insights\n${insights}`;
            
            if (existingIssue) {
              // Update existing issue
              await github.rest.issues.update({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: existingIssue.number,
                body: body
              });
              
              // Add a comment with the new analysis
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: existingIssue.number,
                body: `Updated analysis completed at ${new Date().toISOString()}`
              });
            } else {
              // Create new issue
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: title,
                body: body,
                labels: ['ai-analysis', 'dependencies', 'automated']
              });
            }

      - name: Post high-priority findings as PR comments
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const insights = fs.readFileSync('actionable-insights.md', 'utf8');
            
            // Extract high priority items
            const highPriority = insights.split('\n')
              .filter(line => line.includes('HIGH') || line.includes('CRITICAL'))
              .join('\n');
            
            if (highPriority) {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: `## ‚ö†Ô∏è Dependency Analysis - High Priority Findings\n\n${highPriority}`
              });
            }